import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


# Conducting exploratory analysis on engine data
df = pd.read_csv("/Users/chiral/git_projects/Predicting_Failure_NASA_Turbofan_Jet_Engine/CMaps/train_FD001.txt", delimiter=' ')


column_names = ["unit_number","cycle_number","operational_setting_1","operational_setting_2","operational_setting_3"]
n_cols = len(df.columns)
print(f"Number of Columns: {n_cols}")


# The rest of the columns are sensor measurements, let's label the remaining by an index 
for k in range(1,len(df.columns)-len(column_names)+1):
    column_names.append("sensor_measurement_{}".format(k))

df.columns = column_names
n_engines = len(df["unit_number"].unique())
print(f"Number of Units: {n_engines}")





# Getting the max cyle number of each unit
grouped_data = df.groupby("unit_number")["cycle_number"].max().reset_index()
ordering = grouped_data.sort_values(by="cycle_number", ascending=False)["unit_number"].values
# renaming column
grouped_data = grouped_data.rename(columns={"cycle_number":"max_cycles"})


grouped_data


fig = plt.figure(figsize=(30,8))
sns.barplot(data = grouped_data, x="unit_number", y="max_cycles", order=ordering)


# Creating a dictionary to reference max cycles when calculating RUL
max_dict = grouped_data.set_index('unit_number')['max_cycles'].to_dict()
# max_dict


# max_frame = df_test.groupby("unit_number")["cycle_number"].max().to_dict()
# max_frame


# Adding RUL to dataframe
df["RUL"] = df.apply(lambda row: max_dict[row["unit_number"]]-row["cycle_number"], axis=1)


# Ensuring it was done correctly
df[["unit_number","cycle_number","RUL"]][df["unit_number"]==3]


# Lets drop the irrelevant columns
df.drop(["sensor_measurement_22","sensor_measurement_23"], axis=1, inplace=True)


df


# window_size = 10
# windows = [df.iloc[i:i+window_size] for i in range(len(df) - window_size + 1)]
# windows


# Create a dataset for Unit 1 where the window is 10 cycles long
window_size = 150
unit=1
print(unit)
sub_sample = df[df["unit_number"]==unit]
sub_sample=df.copy()


sub_sample.iloc[i:i+window_size].T



windows = [sub_sample.iloc[i:i+window_size].T.to_numpy() for i in range(len(sub_sample) - window_size + 1)]



# Comparing df to output
window_start=0
df.iloc[window_start:window_start+10].T


df.describe()


print(len(windows))


print(windows[0][0:4])


def create_hdf5(unit_num, np_array):
    '''
    Creating the hdf5 dataset according to the unit number
    '''
    # Store the array into an HDF5 file
    with h5py.File(f'../data/unit_{unit_num}.h5', 'w') as hf:
        hf.create_dataset(f'unit_{unit_num}', data=np_array)
    
    # Load the array from the HDF5 file
    with h5py.File(f'../data/unit_{unit_num}.h5', 'r') as hf:
        loaded_array = hf[f'unit_{unit_num}'][:]
    
    # Verify the loaded array
    print(np.array_equal(np_array, loaded_array)) # Should print True


def load_data(unit_num):
    with h5py.File(f'../data/unit_{unit_num}.h5', 'r') as hf:
        loaded_array = hf[f'unit_{unit_num}'][:]
    return loaded_array


import numpy as np
import h5py

create_hdf5(100, windows)



hf = h5py.File(f'../data/unit_{100}.h5', 'r')
hf.keys()



hf.keys


# print(windows[0][0:4])
print(windows[0])
# print(windows[0:2][-1])



